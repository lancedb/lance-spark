{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lance-Spark Getting Started\n",
    "\n",
    "This notebook demonstrates how to use Lance with Apache Spark for reading and writing Lance datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialize Spark Session\n",
    "\n",
    "The Spark session is already configured with the Lance catalog in the Docker container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/08/07 06:10:42 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n",
      "25/08/07 06:10:42 WARN CheckAllocator: More than one DefaultAllocationManager on classpath. Choosing first found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|      catalog|\n",
      "+-------------+\n",
      "|    lance_dir|\n",
      "|spark_catalog|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "import pandas as pd\n",
    "\n",
    "# Get the existing Spark session\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "        # Directory namespace\n",
    "        .config(\"spark.sql.catalog.lance_dir\", \"com.lancedb.lance.spark.LanceNamespaceSparkCatalog\")\n",
    "        .config(\"spark.sql.catalog.lance_dir.impl\", \"dir\")\n",
    "        .config(\"spark.sql.catalog.lance_dir.root\", \"s3://lance-warehouse/dir_ns\")\n",
    "        .config(\"spark.sql.catalog.lance_dir.storage.endpoint\", \"http://minio:9000\")\n",
    "        .config(\"spark.sql.catalog.lance_dir.storage.aws_allow_http\", \"true\")\n",
    "        .config(\"spark.sql.catalog.lance_dir.storage.access_key_id\", \"admin\")\n",
    "        .config(\"spark.sql.catalog.lance_dir.storage.secret_access_key\", \"password\")\n",
    "        .config(\"spark.sql.catalog.lance_dir.storage.region\", \"us-east-1\")\n",
    "        # Glue namespace\n",
    "        .config(\"spark.sql.catalog.lance_glue\", \"com.lancedb.lance.spark.LanceNamespaceSparkCatalog\")\n",
    "        .config(\"spark.sql.catalog.lance_glue.impl\", \"glue\")\n",
    "        .config(\"spark.sql.catalog.lance_glue.root\", \"s3://lance-warehouse/glue_ns\")\n",
    "        .config(\"spark.sql.catalog.lance_glue.access_key_id\", \"xyz\")\n",
    "        .config(\"spark.sql.catalog.lance_glue.secret_access_key\", \"abc\")\n",
    "        .config(\"spark.sql.catalog.lance_glue.region\", \"us-east-1\")\n",
    "        .config(\"spark.sql.catalog.lance_glue.storage.endpoint\", \"http://minio:9000\")\n",
    "        .config(\"spark.sql.catalog.lance_glue.storage.aws_allow_http\", \"true\")\n",
    "        .config(\"spark.sql.catalog.lance_glue.storage.access_key_id\", \"admin\")\n",
    "        .config(\"spark.sql.catalog.lance_glue.storage.secret_access_key\", \"password\")\n",
    "        .getOrCreate()\n",
    ")\n",
    "\n",
    "# Enable loading the Spark catalog\n",
    "spark.sql(\"set spark.sql.defaultCatalog=lance_dir\")\n",
    "spark.sql(\"use default\")\n",
    "\n",
    "# Uncomment to use Glue catalog\n",
    "# spark.sql(\"set spark.sql.defaultCatalog=lance_glue\")\n",
    "# spark.sql(\"use default\")\n",
    "\n",
    "\n",
    "# Verify Lance catalog is configured\n",
    "spark.sql(\"SHOW CATALOGS\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---+-----------+------+\n",
      "| id|   name|age| department|salary|\n",
      "+---+-------+---+-----------+------+\n",
      "|  1|  Alice| 25|Engineering| 75000|\n",
      "|  2|    Bob| 30|  Marketing| 65000|\n",
      "|  3|Charlie| 35|      Sales| 70000|\n",
      "|  4|  Diana| 28|Engineering| 80000|\n",
      "|  5|    Eve| 32|         HR| 60000|\n",
      "+---+-------+---+-----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a sample DataFrame\n",
    "data = [\n",
    "    (1, \"Alice\", 25, \"Engineering\", 75000),\n",
    "    (2, \"Bob\", 30, \"Marketing\", 65000),\n",
    "    (3, \"Charlie\", 35, \"Sales\", 70000),\n",
    "    (4, \"Diana\", 28, \"Engineering\", 80000),\n",
    "    (5, \"Eve\", 32, \"HR\", 60000)\n",
    "]\n",
    "\n",
    "columns = [\"id\", \"name\", \"age\", \"department\", \"salary\"]\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.sql(\"CREATE TABLE employees (id INT, name STRING, age INT, department STRING, salary INT)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Show Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+\n",
      "|namespace|tableName|isTemporary|\n",
      "+---------+---------+-----------+\n",
      "|  default|employees|      false|\n",
      "+---------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW TABLES\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Describe Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+-------+\n",
      "|            col_name|data_type|comment|\n",
      "+--------------------+---------+-------+\n",
      "|                  id|      int|   NULL|\n",
      "|                name|   string|   NULL|\n",
      "|                 age|      int|   NULL|\n",
      "|          department|   string|   NULL|\n",
      "|              salary|      int|   NULL|\n",
      "|                    |         |       |\n",
      "|  # Metadata Columns|         |       |\n",
      "|              _rowid|   bigint|       |\n",
      "|            _rowaddr|   bigint|       |\n",
      "|                    |         |       |\n",
      "|# Detailed Table ...|         |       |\n",
      "|                Name|employees|       |\n",
      "|                Type|  MANAGED|       |\n",
      "|    Table Properties|       []|       |\n",
      "+--------------------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"DESCRIBE TABLE EXTENDED employees\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Write Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.writeTo(\"employees\").append()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Simple Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---+-----------+------+\n",
      "| id|   name|age| department|salary|\n",
      "+---+-------+---+-----------+------+\n",
      "|  1|  Alice| 25|Engineering| 75000|\n",
      "|  2|    Bob| 30|  Marketing| 65000|\n",
      "|  3|Charlie| 35|      Sales| 70000|\n",
      "|  4|  Diana| 28|Engineering| 80000|\n",
      "|  5|    Eve| 32|         HR| 60000|\n",
      "+---+-------+---+-----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.table(\"employees\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Complex Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------+----------+\n",
      "| department|employee_count|avg_salary|\n",
      "+-----------+--------------+----------+\n",
      "|Engineering|             2|   77500.0|\n",
      "|      Sales|             1|   70000.0|\n",
      "|  Marketing|             1|   65000.0|\n",
      "|         HR|             1|   60000.0|\n",
      "+-----------+--------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = spark.sql(\"\"\"\n",
    "    SELECT department, \n",
    "           COUNT(*) as employee_count,\n",
    "           AVG(salary) as avg_salary\n",
    "    FROM employees\n",
    "    GROUP BY department\n",
    "    ORDER BY avg_salary DESC\n",
    "\"\"\")\n",
    "\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Append More Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---+-----------+------+\n",
      "| id| name|age| department|salary|\n",
      "+---+-----+---+-----------+------+\n",
      "|  7|Grace| 31|  Marketing| 68000|\n",
      "|  6|Frank| 29|Engineering| 77000|\n",
      "+---+-----+---+-----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_data = [\n",
    "    (6, \"Frank\", 29, \"Engineering\", 77000),\n",
    "    (7, \"Grace\", 31, \"Marketing\", 68000)\n",
    "]\n",
    "\n",
    "new_df = spark.createDataFrame(new_data, columns)\n",
    "\n",
    "new_df.writeTo(\"employees\").append()\n",
    "\n",
    "spark.sql(\"SELECT * FROM employees ORDER BY id DESC LIMIT 2\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"DROP TABLE IF EXISTS employees\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
